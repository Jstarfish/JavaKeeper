{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[149],{677:function(r,o,e){\"use strict\";e.r(o);var n=e(6),t=Object(n.a)({},(function(){var r=this,o=r.$createElement,e=r._self._c||o;return e(\"ContentSlotsDistributor\",{attrs:{\"slot-key\":r.$parent.slotKey}},[e(\"blockquote\",[e(\"p\",[r._v(\"https://www.cnblogs.com/huxi2b/p/6223228.html\")])]),r._v(\" \"),e(\"h2\",{attrs:{id:\"消费者组\"}},[e(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#消费者组\"}},[r._v(\"#\")]),r._v(\" 消费者组\")]),r._v(\" \"),e(\"p\",[e(\"strong\",[r._v(\"1 什么是消费者组\")])]),r._v(\" \"),e(\"p\",[r._v(\"其实对于这些基本概念的普及，网上资料实在太多了。我本不应该再画蛇添足了，但为了本文的完整性，我还是要花一些篇幅来重谈consumer group，至少可以说说我的理解。值得一提的是，由于我们今天基本上只探讨consumer group，对于单独的消费者不做过多讨论。\")]),r._v(\" \"),e(\"p\",[r._v(\"什么是consumer group? 一言以蔽之，consumer group是kafka提供的可扩展且具有容错性的消费者机制。既然是一个组，那么组内必然可以有多个消费者或消费者实例(consumer instance)，它们共享一个公共的ID，即group ID。组内的所有消费者协调在一起来消费订阅主题(subscribed topics)的所有分区(partition)。当然，每个分区只能由同一个消费组内的一个consumer来消费。（网上文章中说到此处各种炫目多彩的图就会紧跟着抛出来，我这里就不画了，请原谅）。个人认为，理解consumer group记住下面这三个特性就好了：\")]),r._v(\" \"),e(\"ul\",[e(\"li\",[r._v(\"consumer group下可以有一个或多个consumer instance，consumer instance可以是一个进程，也可以是一个线程\")]),r._v(\" \"),e(\"li\",[r._v(\"group.id是一个字符串，唯一标识一个consumer group\")]),r._v(\" \"),e(\"li\",[r._v(\"consumer group下订阅的topic下的每个分区只能分配给某个group下的一个consumer(当然该分区还可以被分配给其他group)\")])]),r._v(\" \"),e(\"p\",[e(\"strong\",[r._v(\"2 消费者位置(consumer position)\")])]),r._v(\" \"),e(\"p\",[r._v(\"消费者在消费的过程中需要记录自己消费了多少数据，即消费位置信息。在Kafka中这个位置信息有个专门的术语：位移(offset)。很多消息引擎都把这部分信息保存在服务器端(broker端)。这样做的好处当然是实现简单，但会有三个主要的问题：\")]),r._v(\" \"),e(\"ol\",[e(\"li\",[r._v(\"broker从此变成有状态的，会影响伸缩性；\")]),r._v(\" \"),e(\"li\",[r._v(\"需要引入应答机制(acknowledgement)来确认消费成功。\")]),r._v(\" \"),e(\"li\",[r._v(\"由于要保存很多consumer的offset信息，必然引入复杂的数据结构，造成资源浪费。而Kafka选择了不同的方式：每个consumer group保存自己的位移信息，那么只需要简单的一个整数表示位置就够了；同时可以引入checkpoint机制定期持久化，简化了应答机制的实现。\")])]),r._v(\" \"),e(\"p\",[e(\"strong\",[r._v(\"3 位移管理(offset management)\")])]),r._v(\" \"),e(\"p\",[e(\"strong\",[r._v(\"3.1 自动VS手动\")])]),r._v(\" \"),e(\"p\",[r._v(\"Kafka默认是定期帮你自动提交位移的(enable.auto.commit = true)，你当然可以选择手动提交位移实现自己控制。另外kafka会定期把group消费情况保存起来，做成一个offset map，如下图所示：\")]),r._v(\" \"),e(\"p\",[e(\"img\",{attrs:{src:\"https://images2015.cnblogs.com/blog/735367/201612/735367-20161226175429711-638862783.png\",alt:\"\"}})]),r._v(\" \"),e(\"p\",[r._v(\"上图中表明了test-group这个组当前的消费情况。\")]),r._v(\" \"),e(\"p\",[e(\"strong\",[r._v(\"3.2 位移提交\")])]),r._v(\" \"),e(\"p\",[r._v(\"老版本的位移是提交到zookeeper中的，图就不画了，总之目录结构是：/consumers/<\"),e(\"a\",{attrs:{href:\"http://group.id/\",target:\"_blank\",rel:\"noopener noreferrer\"}},[r._v(\"group.id\"),e(\"OutboundLink\")],1),r._v(\">/offsets/\"),e(\"topic\",[r._v(\"/\"),e(\"partitionId\",[r._v(\"，但是zookeeper其实并不适合进行大批量的读写操作，尤其是写操作。因此kafka提供了另一种解决方案：增加__consumeroffsets topic，将offset信息写入这个topic，摆脱对zookeeper的依赖(指保存offset这件事情)。__consumer_offsets中的消息保存了每个consumer group某一时刻提交的offset信息。依然以上图中的consumer group为例，格式大概如下：\")])],1)],1),r._v(\" \"),e(\"p\",[e(\"img\",{attrs:{src:\"https://images2015.cnblogs.com/blog/735367/201612/735367-20161226175522507-1842910668.png\",alt:\"img\"}})]),r._v(\" \"),e(\"p\",[r._v(\"__consumers_offsets topic配置了compact策略，使得它总是能够保存最新的位移信息，既控制了该topic总体的日志容量，也能实现保存最新offset的目的。compact的具体原理请参见：\"),e(\"a\",{attrs:{href:\"https://kafka.apache.org/documentation/#compaction\",target:\"_blank\",rel:\"noopener noreferrer\"}},[r._v(\"Log Compaction\"),e(\"OutboundLink\")],1)]),r._v(\" \"),e(\"p\",[r._v(\"至于每个group保存到__consumers_offsets的哪个分区，如何查看的问题请参见这篇文章：\"),e(\"a\",{attrs:{href:\"http://www.cnblogs.com/huxi2b/p/6061110.html\",target:\"_blank\",rel:\"noopener noreferrer\"}},[r._v(\"Kafka 如何读取offset topic内容 (__consumer_offsets)\"),e(\"OutboundLink\")],1)]),r._v(\" \"),e(\"p\",[e(\"strong\",[r._v(\"4 Rebalance\")])]),r._v(\" \"),e(\"p\",[e(\"strong\",[r._v(\"4.1 什么是rebalance？\")])]),r._v(\" \"),e(\"p\",[r._v(\"rebalance本质上是一种协议，规定了一个consumer group下的所有consumer如何达成一致来分配订阅topic的每个分区。比如某个group下有20个consumer，它订阅了一个具有100个分区的topic。正常情况下，Kafka平均会为每个consumer分配5个分区。这个分配的过程就叫rebalance。\")]),r._v(\" \"),e(\"p\",[e(\"strong\",[r._v(\"4.2 什么时候rebalance？\")])]),r._v(\" \"),e(\"p\",[r._v(\"这也是经常被提及的一个问题。rebalance的触发条件有三种：\")]),r._v(\" \"),e(\"ul\",[e(\"li\",[r._v(\"组成员发生变更(新consumer加入组、已有consumer主动离开组或已有consumer崩溃了——这两者的区别后面会谈到)\")]),r._v(\" \"),e(\"li\",[r._v(\"订阅主题数发生变更——这当然是可能的，如果你使用了正则表达式的方式进行订阅，那么新建匹配正则表达式的topic就会触发rebalance\")]),r._v(\" \"),e(\"li\",[r._v(\"订阅主题的分区数发生变更\")])]),r._v(\" \"),e(\"p\",[e(\"strong\",[r._v(\"4.3 如何进行组内分区分配？\")])]),r._v(\" \"),e(\"p\",[r._v(\"之前提到了group下的所有consumer都会协调在一起共同参与分配，这是如何完成的？Kafka新版本consumer默认提供了两种分配策略：range和round-robin。当然Kafka采用了可插拔式的分配策略，你可以创建自己的分配器以实现不同的分配策略。实际上，由于目前range和round-robin两种分配器都有一些弊端，Kafka社区已经提出第三种分配器来实现更加公平的分配策略，只是目前还在开发中。我们这里只需要知道consumer group默认已经帮我们把订阅topic的分区分配工作做好了就行了。\")]),r._v(\" \"),e(\"p\",[r._v(\"简单举个例子，假设目前某个consumer group下有两个consumer： A和B，当第三个成员加入时，kafka会触发rebalance并根据默认的分配策略重新为A、B和C分配分区，如下图所示：\")]),r._v(\" \"),e(\"p\",[e(\"img\",{attrs:{src:\"https://images2015.cnblogs.com/blog/735367/201612/735367-20161226175710289-1164779517.png\",alt:\"img\"}})]),r._v(\" \"),e(\"p\",[e(\"strong\",[r._v(\"4.4 谁来执行rebalance和consumer group管理？\")])]),r._v(\" \"),e(\"p\",[r._v(\"Kafka提供了一个角色：coordinator来执行对于consumer group的管理。坦率说kafka对于coordinator的设计与修改是一个很长的故事。最新版本的coordinator也与最初的设计有了很大的不同。这里我只想提及两次比较大的改变。\")]),r._v(\" \"),e(\"p\",[r._v(\"首先是0.8版本的coordinator，那时候的coordinator是依赖zookeeper来实现对于consumer group的管理的。Coordinator监听zookeeper的/consumers/\"),e(\"group\",[r._v(\"/ids的子节点变化以及/brokers/topics/\"),e(\"topic\",[r._v(\"数据变化来判断是否需要进行rebalance。group下的每个consumer都自己决定要消费哪些分区，并把自己的决定抢先在zookeeper中的/consumers/\"),e(\"group\",[r._v(\"/owners/\"),e(\"topic\",[r._v(\"/\"),e(\"partition\",[r._v(\"下注册。很明显，这种方案要依赖于zookeeper的帮助，而且每个consumer是单独做决定的，没有那种“大家属于一个组，要协商做事情”的精神。\")])],1)],1)],1)],1)],1),r._v(\" \"),e(\"p\",[r._v(\"基于这些潜在的弊端，0.9版本的kafka改进了coordinator的设计，提出了group coordinator——每个consumer group都会被分配一个这样的coordinator用于组管理和位移管理。这个group coordinator比原来承担了更多的责任，比如组成员管理、位移提交保护机制等。当新版本consumer group的第一个consumer启动的时候，它会去和kafka server确定谁是它们组的coordinator。之后该group内的所有成员都会和该coordinator进行协调通信。显而易见，这种coordinator设计不再需要zookeeper了，性能上可以得到很大的提升。后面的所有部分我们都将讨论最新版本的coordinator设计。\")]),r._v(\" \"),e(\"p\",[e(\"strong\",[r._v(\"4.5 如何确定coordinator？\")])]),r._v(\" \"),e(\"p\",[r._v(\"上面简单讨论了新版coordinator的设计，那么consumer group如何确定自己的coordinator是谁呢？ 简单来说分为两步：\")]),r._v(\" \"),e(\"ul\",[e(\"li\",[r._v(\"确定consumer group位移信息写入__consumers_offsets的哪个分区。具体计算公式：\\n\"),e(\"ul\",[e(\"li\",[r._v(\"__consumers_offsets partition# = Math.abs(groupId.hashCode() % groupMetadataTopicPartitionCount)  注意：groupMetadataTopicPartitionCount由offsets.topic.num.partitions指定，默认是50个分区。\")])])]),r._v(\" \"),e(\"li\",[r._v(\"该分区leader所在的broker就是被选定的coordinator\")])]),r._v(\" \"),e(\"p\",[e(\"strong\",[r._v(\"4.6 Rebalance Generation\")])]),r._v(\" \"),e(\"p\",[r._v(\"JVM GC的分代收集就是这个词(严格来说是generational)，我这里把它翻译成“届”好了，它表示了rebalance之后的一届成员，主要是用于保护consumer group，隔离无效offset提交的。比如上一届的consumer成员是无法提交位移到新一届的consumer group中。我们有时候可以看到ILLEGAL_GENERATION的错误，就是kafka在抱怨这件事情。每次group进行rebalance之后，generation号都会加1，表示group进入到了一个新的版本，如下图所示： Generation 1时group有3个成员，随后成员2退出组，coordinator触发rebalance，consumer group进入Generation 2，之后成员4加入，再次触发rebalance，group进入Generation 3.\")]),r._v(\" \"),e(\"p\",[e(\"img\",{attrs:{src:\"https://images2015.cnblogs.com/blog/735367/201612/735367-20161226175822570-898409869.png\",alt:\"img\"}})]),r._v(\" \"),e(\"p\",[e(\"strong\",[r._v(\"4.7 协议(protocol)\")])]),r._v(\" \"),e(\"p\",[r._v(\"前面说过了， rebalance本质上是一组协议。group与coordinator共同使用它来完成group的rebalance。目前kafka提供了5个协议来处理与consumer group coordination相关的问题：\")]),r._v(\" \"),e(\"ul\",[e(\"li\",[r._v(\"Heartbeat请求：consumer需要定期给coordinator发送心跳来表明自己还活着\")]),r._v(\" \"),e(\"li\",[r._v(\"LeaveGroup请求：主动告诉coordinator我要离开consumer group\")]),r._v(\" \"),e(\"li\",[r._v(\"SyncGroup请求：group leader把分配方案告诉组内所有成员\")]),r._v(\" \"),e(\"li\",[r._v(\"JoinGroup请求：成员请求加入组\")]),r._v(\" \"),e(\"li\",[r._v(\"DescribeGroup请求：显示组的所有信息，包括成员信息，协议名称，分配方案，订阅信息等。通常该请求是给管理员使用\")])]),r._v(\" \"),e(\"p\",[r._v(\"Coordinator在rebalance的时候主要用到了前面4种请求。\\n\"),e(\"strong\",[r._v(\"4.8 liveness\")])]),r._v(\" \"),e(\"p\",[r._v(\"consumer如何向coordinator证明自己还活着？ 通过定时向coordinator发送Heartbeat请求。如果超过了设定的超时时间，那么coordinator就认为这个consumer已经挂了。一旦coordinator认为某个consumer挂了，那么它就会开启新一轮rebalance，并且在当前其他consumer的心跳response中添加“REBALANCE_IN_PROGRESS”，告诉其他consumer：不好意思各位，你们重新申请加入组吧！\")]),r._v(\" \"),e(\"p\",[e(\"strong\",[r._v(\"4.9 Rebalance过程\")])]),r._v(\" \"),e(\"p\",[r._v(\"终于说到consumer group执行rebalance的具体流程了。很多用户估计对consumer内部的工作机制也很感兴趣。下面就跟大家一起讨论一下。当然我必须要明确表示，rebalance的前提是coordinator已经确定了。\")]),r._v(\" \"),e(\"p\",[r._v(\"总体而言，rebalance分为2步：Join和Sync\")]),r._v(\" \"),e(\"p\",[r._v(\"1 Join， 顾名思义就是加入组。这一步中，所有成员都向coordinator发送JoinGroup请求，请求入组。一旦所有成员都发送了JoinGroup请求，coordinator会从中选择一个consumer担任leader的角色，并把组成员信息以及订阅信息发给leader——注意leader和coordinator不是一个概念。leader负责消费分配方案的制定。\")]),r._v(\" \"),e(\"p\",[r._v(\"2 Sync，这一步leader开始分配消费方案，即哪个consumer负责消费哪些topic的哪些partition。一旦完成分配，leader会将这个方案封装进SyncGroup请求中发给coordinator，非leader也会发SyncGroup请求，只是内容为空。coordinator接收到分配方案之后会把方案塞进SyncGroup的response中发给各个consumer。这样组内的所有成员就都知道自己应该消费哪些分区了。\")]),r._v(\" \"),e(\"p\",[r._v(\"还是拿几张图来说明吧，首先是加入组的过程:\")]),r._v(\" \"),e(\"p\",[e(\"img\",{attrs:{src:\"https://images2015.cnblogs.com/blog/735367/201612/735367-20161226175922086-1237318351.png\",alt:\"img\"}})]),r._v(\" \"),e(\"p\",[r._v(\"值得注意的是， 在coordinator收集到所有成员请求前，它会把已收到请求放入一个叫purgatory(炼狱)的地方。记得国内有篇文章以此来证明kafka开发人员都是很有文艺范的，写得也是比较有趣，有兴趣可以去搜搜。\\n然后是分发分配方案的过程，即SyncGroup请求：\")]),r._v(\" \"),e(\"p\",[e(\"img\",{attrs:{src:\"https://images2015.cnblogs.com/blog/735367/201612/735367-20161226180005242-1302422077.png\",alt:\"img\"}})]),r._v(\" \"),e(\"p\",[r._v(\"注意！！ consumer group的分区分配方案是在客户端执行的！Kafka将这个权利下放给客户端主要是因为这样做可以有更好的灵活性。比如这种机制下我可以实现类似于Hadoop那样的机架感知(rack-aware)分配方案，即为consumer挑选同一个机架下的分区数据，减少网络传输的开销。Kafka默认为你提供了两种分配策略：range和round-robin。由于这不是本文的重点，这里就不再详细展开了，你只需要记住你可以覆盖consumer的参数：partition.assignment.strategy来实现自己分配策略就好了。\")]),r._v(\" \"),e(\"p\",[e(\"strong\",[r._v(\"4.10 consumer group状态机\")])]),r._v(\" \"),e(\"p\",[r._v(\"和很多kafka组件一样，group也做了个状态机来表明组状态的流转。coordinator根据这个状态机会对consumer group做不同的处理，如下图所示(完全是根据代码注释手动画的，多见谅吧)\")]),r._v(\" \"),e(\"p\",[e(\"img\",{attrs:{src:\"https://images2015.cnblogs.com/blog/735367/201612/735367-20161226180046945-1657832046.png\",alt:\"img\"}})]),r._v(\" \"),e(\"p\",[r._v(\"简单说明下图中的各个状态：\")]),r._v(\" \"),e(\"ul\",[e(\"li\",[r._v(\"Dead：组内已经没有任何成员的最终状态，组的元数据也已经被coordinator移除了。这种状态响应各种请求都是一个response： UNKNOWN_MEMBER_ID\")]),r._v(\" \"),e(\"li\",[r._v(\"Empty：组内无成员，但是位移信息还没有过期。这种状态只能响应JoinGroup请求\")]),r._v(\" \"),e(\"li\",[r._v(\"PreparingRebalance：组准备开启新的rebalance，等待成员加入\")]),r._v(\" \"),e(\"li\",[r._v(\"AwaitingSync：正在等待leader consumer将分配方案传给各个成员\")]),r._v(\" \"),e(\"li\",[r._v(\"Stable：rebalance完成！可以开始消费了~\")])]),r._v(\" \"),e(\"p\",[r._v(\"至于各个状态之间的流程条件以及action，这里就不具体展开了。\")]),r._v(\" \"),e(\"p\",[e(\"strong\",[r._v(\"三、rebalance场景剖析\")])]),r._v(\" \"),e(\"p\",[r._v(\"上面详细阐述了consumer group是如何执行rebalance的，可能依然有些云里雾里。这部分对其中的三个重要的场景做详尽的时序展开，进一步加深对于consumer group内部原理的理解。由于图比较直观，所有的描述都将以图的方式给出，不做过多的文字化描述了。\")]),r._v(\" \"),e(\"p\",[e(\"strong\",[r._v(\"1 新成员加入组(member join)\")])]),r._v(\" \"),e(\"p\",[e(\"strong\",[e(\"img\",{attrs:{src:\"https://images2017.cnblogs.com/blog/735367/201801/735367-20180122172838209-863721577.png\",alt:\"img\"}})])]),r._v(\" \"),e(\"p\",[e(\"strong\",[r._v(\"2 组成员崩溃(member failure)\")])]),r._v(\" \"),e(\"p\",[r._v(\"前面说过了，组成员崩溃和组成员主动离开是两个不同的场景。因为在崩溃时成员并不会主动地告知coordinator此事，coordinator有可能需要一个完整的session.timeout周期才能检测到这种崩溃，这必然会造成consumer的滞后。可以说离开组是主动地发起rebalance；而崩溃则是被动地发起rebalance。okay，直接上图：\")]),r._v(\" \"),e(\"p\",[e(\"img\",{attrs:{src:\"https://images2017.cnblogs.com/blog/735367/201801/735367-20180122172921209-2006292699.png\",alt:\"img\"}})]),r._v(\" \"),e(\"p\",[e(\"strong\",[r._v(\"3 组成员主动离组（member leave group)\")])]),r._v(\" \"),e(\"p\",[e(\"img\",{attrs:{src:\"https://images2017.cnblogs.com/blog/735367/201801/735367-20180122172958600-838820663.png\",alt:\"img\"}})]),r._v(\" \"),e(\"p\",[e(\"strong\",[r._v(\"4 提交位移(member commit offset)\")])]),r._v(\" \"),e(\"p\",[e(\"img\",{attrs:{src:\"https://images2017.cnblogs.com/blog/735367/201801/735367-20180122173024959-506110104.png\",alt:\"img\"}})]),r._v(\" \"),e(\"p\",[r._v(\"总结一下，本文着重讨论了一下新版本的consumer group的内部设计原理，特别是consumer group与coordinator之间的交互过程，希望对各位有所帮助\")]),r._v(\" \"),e(\"blockquote\",[e(\"p\",[r._v(\"https://www.cnblogs.com/huxi2b/p/6124937.html\")]),r._v(\" \"),e(\"p\",[r._v(\"https://www.cnblogs.com/huxi2b/p/7089854.html\")])]),r._v(\" \"),e(\"p\",[r._v(\"Kafka 0.9版本开始推出了Java版本的consumer，优化了coordinator的设计以及摆脱了对zookeeper的依赖。社区最近也在探讨正式用这套consumer API替换Scala版本的consumer的计划。鉴于目前这方面的资料并不是很多，本文将尝试给出一个利用KafkaConsumer编写的多线程消费者实例，希望对大家有所帮助。\")]),r._v(\" \"),e(\"p\",[r._v(\"这套API最重要的入口就是KafkaConsumer(o.a.k.clients.consumer.KafkaConsumer)，普通的单线程使用方法官网API已有介绍，这里不再赘述了。因此，我们直奔主题——讨论一下如何创建多线程的方式来使用KafkaConsumer。KafkaConsumer和KafkaProducer不同，后者是线程安全的，因此我们鼓励用户在多个线程中共享一个KafkaProducer实例，这样通常都要比每个线程维护一个KafkaProducer实例效率要高。但对于KafkaConsumer而言，它不是线程安全的，所以实现多线程时通常由两种实现方法：\")]),r._v(\" \"),e(\"p\",[r._v(\"1 每个线程维护一个KafkaConsumer\")]),r._v(\" \"),e(\"p\",[e(\"img\",{attrs:{src:\"https://images2015.cnblogs.com/blog/735367/201612/735367-20161202105906443-1609157006.png\",alt:\"img\"}})]),r._v(\" \"),e(\"p\",[r._v(\"2 维护一个或多个KafkaConsumer，同时维护多个事件处理线程(worker thread)\")]),r._v(\" \"),e(\"p\",[e(\"img\",{attrs:{src:\"https://images2015.cnblogs.com/blog/735367/201612/735367-20161202110008787-550483601.png\",alt:\"img\"}})]),r._v(\" \"),e(\"p\",[r._v(\"当然，这种方法还可以有多个变种：比如每个worker线程有自己的处理队列。consumer根据某种规则或逻辑将消息放入不同的队列。不过总体思想还是相同的，故这里不做过多展开讨论了。\")]),r._v(\" \"),e(\"p\",[r._v(\"下表总结了两种方法的优缺点：\")]),r._v(\" \"),e(\"table\",[e(\"thead\",[e(\"tr\",[e(\"th\"),r._v(\" \"),e(\"th\",[r._v(\"优点\")]),r._v(\" \"),e(\"th\",[r._v(\"缺点\")])])]),r._v(\" \"),e(\"tbody\",[e(\"tr\",[e(\"td\",[r._v(\"方法1(每个线程维护一个KafkaConsumer)\")]),r._v(\" \"),e(\"td\",[r._v(\"方便实现 速度较快，因为不需要任何线程间交互 易于维护分区内的消息顺序\")]),r._v(\" \"),e(\"td\",[r._v(\"更多的TCP连接开销(每个线程都要维护若干个TCP连接) consumer数受限于topic分区数，扩展性差 频繁请求导致吞吐量下降 线程自己处理消费到的消息可能会导致超时，从而造成rebalance\")])]),r._v(\" \"),e(\"tr\",[e(\"td\",[r._v(\"方法2 (单个(或多个)consumer，多个worker线程)\")]),r._v(\" \"),e(\"td\",[r._v(\"可独立扩展consumer数和worker数，伸缩性好\")]),r._v(\" \"),e(\"td\",[r._v(\"实现麻烦通常难于维护分区内的消息顺序处理链路变长，导致难以保证提交位移的语义正确性\")])])])]),r._v(\" \"),e(\"p\",[r._v(\"下面我们分别实现这两种方法。需要指出的是，下面的代码都是最基本的实现，并没有考虑很多编程细节，比如如何处理错误等。\")]),r._v(\" \"),e(\"p\",[e(\"strong\",[r._v(\"方法1\")])]),r._v(\" \"),e(\"p\",[e(\"strong\",[r._v(\"ConsumerRunnable类\")])]),r._v(\" \"),e(\"div\",{staticClass:\"language- extra-class\"},[e(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[e(\"code\",[r._v(' 1 import org.apache.kafka.clients.consumer.ConsumerRecord;\\n 2 import org.apache.kafka.clients.consumer.ConsumerRecords;\\n 3 import org.apache.kafka.clients.consumer.KafkaConsumer;\\n 4 \\n 5 import java.util.Arrays;\\n 6 import java.util.Properties;\\n 7 \\n 8 public class ConsumerRunnable implements Runnable {\\n 9 \\n10     // 每个线程维护私有的KafkaConsumer实例\\n11     private final KafkaConsumer<String, String> consumer;\\n12 \\n13     public ConsumerRunnable(String brokerList, String groupId, String topic) {\\n14         Properties props = new Properties();\\n15         props.put(\"bootstrap.servers\", brokerList);\\n16         props.put(\"group.id\", groupId);\\n17         props.put(\"enable.auto.commit\", \"true\");        //本例使用自动提交位移\\n18         props.put(\"auto.commit.interval.ms\", \"1000\");\\n19         props.put(\"session.timeout.ms\", \"30000\");\\n20         props.put(\"key.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\\n21         props.put(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\\n22         this.consumer = new KafkaConsumer<>(props);\\n23         consumer.subscribe(Arrays.asList(topic));   // 本例使用分区副本自动分配策略\\n24     }\\n25 \\n26     @Override\\n27     public void run() {\\n28         while (true) {\\n29             ConsumerRecords<String, String> records = consumer.poll(200);   // 本例使用200ms作为获取超时时间\\n30             for (ConsumerRecord<String, String> record : records) {\\n31                 // 这里面写处理消息的逻辑，本例中只是简单地打印消息\\n32                 System.out.println(Thread.currentThread().getName() + \" consumed \" + record.partition() +\\n33                         \"th message with offset: \" + record.offset());\\n34             }\\n35         }\\n36     }\\n37 }\\n')])])]),e(\"p\",[e(\"strong\",[r._v(\"ConsumerGroup类\")])]),r._v(\" \"),e(\"div\",{staticClass:\"language- extra-class\"},[e(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[e(\"code\",[r._v(\" 1 package com.my.kafka.test;\\n 2 \\n 3 import java.util.ArrayList;\\n 4 import java.util.List;\\n 5 \\n 6 public class ConsumerGroup {\\n 7 \\n 8     private List<ConsumerRunnable> consumers;\\n 9 \\n10     public ConsumerGroup(int consumerNum, String groupId, String topic, String brokerList) {\\n11         consumers = new ArrayList<>(consumerNum);\\n12         for (int i = 0; i < consumerNum; ++i) {\\n13             ConsumerRunnable consumerThread = new ConsumerRunnable(brokerList, groupId, topic);\\n14             consumers.add(consumerThread);\\n15         }\\n16     }\\n17 \\n18     public void execute() {\\n19         for (ConsumerRunnable task : consumers) {\\n20             new Thread(task).start();\\n21         }\\n22     }\\n23 }\\n\")])])]),e(\"p\",[e(\"strong\",[r._v(\"ConsumerMain类\")])]),r._v(\" \"),e(\"div\",{staticClass:\"language- extra-class\"},[e(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[e(\"code\",[r._v(' 1 public class ConsumerMain {\\n 2 \\n 3     public static void main(String[] args) {\\n 4         String brokerList = \"localhost:9092\";\\n 5         String groupId = \"testGroup1\";\\n 6         String topic = \"test-topic\";\\n 7         int consumerNum = 3;\\n 8 \\n 9         ConsumerGroup consumerGroup = new ConsumerGroup(consumerNum, groupId, topic, brokerList);\\n10         consumerGroup.execute();\\n11     }\\n12 }\\n')])])]),e(\"p\",[e(\"strong\",[r._v(\"方法2\")])]),r._v(\" \"),e(\"p\",[e(\"strong\",[r._v(\"Worker类\")])]),r._v(\" \"),e(\"div\",{staticClass:\"language- extra-class\"},[e(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[e(\"code\",[r._v(' 1 import org.apache.kafka.clients.consumer.ConsumerRecord;\\n 2 \\n 3 public class Worker implements Runnable {\\n 4 \\n 5     private ConsumerRecord<String, String> consumerRecord;\\n 6 \\n 7     public Worker(ConsumerRecord record) {\\n 8         this.consumerRecord = record;\\n 9     }\\n10 \\n11     @Override\\n12     public void run() {\\n13         // 这里写你的消息处理逻辑，本例中只是简单地打印消息\\n14         System.out.println(Thread.currentThread().getName() + \" consumed \" + consumerRecord.partition()\\n15             + \"th message with offset: \" + consumerRecord.offset());\\n16     }\\n17 }\\n')])])]),e(\"p\",[e(\"strong\",[r._v(\"ConsumerHandler类\")])]),r._v(\" \"),e(\"div\",{staticClass:\"language- extra-class\"},[e(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[e(\"code\",[r._v(' 1 import org.apache.kafka.clients.consumer.ConsumerRecord;\\n 2 import org.apache.kafka.clients.consumer.ConsumerRecords;\\n 3 import org.apache.kafka.clients.consumer.KafkaConsumer;\\n 4 \\n 5 import java.util.Arrays;\\n 6 import java.util.Properties;\\n 7 import java.util.concurrent.ArrayBlockingQueue;\\n 8 import java.util.concurrent.ExecutorService;\\n 9 import java.util.concurrent.ThreadPoolExecutor;\\n10 import java.util.concurrent.TimeUnit;\\n11 \\n12 public class ConsumerHandler {\\n13 \\n14     // 本例中使用一个consumer将消息放入后端队列，你当然可以使用前一种方法中的多实例按照某张规则同时把消息放入后端队列\\n15     private final KafkaConsumer<String, String> consumer;\\n16     private ExecutorService executors;\\n17 \\n18     public ConsumerHandler(String brokerList, String groupId, String topic) {\\n19         Properties props = new Properties();\\n20         props.put(\"bootstrap.servers\", brokerList);\\n21         props.put(\"group.id\", groupId);\\n22         props.put(\"enable.auto.commit\", \"true\");\\n23         props.put(\"auto.commit.interval.ms\", \"1000\");\\n24         props.put(\"session.timeout.ms\", \"30000\");\\n25         props.put(\"key.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\\n26         props.put(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\\n27         consumer = new KafkaConsumer<>(props);\\n28         consumer.subscribe(Arrays.asList(topic));\\n29     }\\n30 \\n31     public void execute(int workerNum) {\\n32         executors = new ThreadPoolExecutor(workerNum, workerNum, 0L, TimeUnit.MILLISECONDS,\\n33                 new ArrayBlockingQueue<>(1000), new ThreadPoolExecutor.CallerRunsPolicy());\\n34 \\n35         while (true) {\\n36             ConsumerRecords<String, String> records = consumer.poll(200);\\n37             for (final ConsumerRecord record : records) {\\n38                 executors.submit(new Worker(record));\\n39             }\\n40         }\\n41     }\\n42 \\n43     public void shutdown() {\\n44         if (consumer != null) {\\n45             consumer.close();\\n46         }\\n47         if (executors != null) {\\n48             executors.shutdown();\\n49         }\\n50         try {\\n51             if (!executors.awaitTermination(10, TimeUnit.SECONDS)) {\\n52                 System.out.println(\"Timeout.... Ignore for this case\");\\n53             }\\n54         } catch (InterruptedException ignored) {\\n55             System.out.println(\"Other thread interrupted this shutdown, ignore for this case.\");\\n56             Thread.currentThread().interrupt();\\n57         }\\n58     }\\n59 \\n60 }\\n')])])]),e(\"p\",[e(\"strong\",[r._v(\"Main类\")])]),r._v(\" \"),e(\"div\",{staticClass:\"language- extra-class\"},[e(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[e(\"code\",[r._v(' 1 public class Main {\\n 2 \\n 3     public static void main(String[] args) {\\n 4         String brokerList = \"localhost:9092,localhost:9093,localhost:9094\";\\n 5         String groupId = \"group2\";\\n 6         String topic = \"test-topic\";\\n 7         int workerNum = 5;\\n 8 \\n 9         ConsumerHandler consumers = new ConsumerHandler(brokerList, groupId, topic);\\n10         consumers.execute(workerNum);\\n11         try {\\n12             Thread.sleep(1000000);\\n13         } catch (InterruptedException ignored) {}\\n14         consumers.shutdown();\\n15     }\\n16 }\\n')])])]),e(\"p\",[r._v(\"总结一下，这两种方法或是模型都有各自的优缺点，在具体使用时需要根据自己实际的业务特点来选取对应的方法。就我个人而言，我比较推崇第二种方法以及背后的思想，即不要将很重的处理逻辑放入消费者的代码中，很多Kafka consumer使用者碰到的各种rebalance超时、coordinator重新选举、心跳无法维持等问题都来源于此。\")])])}),[],!1,null,null,null);o.default=t.exports}}]);","extractedComments":[]}