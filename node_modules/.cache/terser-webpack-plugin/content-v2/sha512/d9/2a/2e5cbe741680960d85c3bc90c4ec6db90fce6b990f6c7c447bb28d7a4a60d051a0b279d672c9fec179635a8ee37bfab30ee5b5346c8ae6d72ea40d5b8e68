{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[67],{604:function(t,s,a){\"use strict\";a.r(s);var n=a(6),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a(\"ContentSlotsDistributor\",{attrs:{\"slot-key\":t.$parent.slotKey}},[a(\"h2\",{attrs:{id:\"一、phoenix-简介\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#一、phoenix-简介\"}},[t._v(\"#\")]),t._v(\" 一、Phoenix 简介\")]),t._v(\" \"),a(\"p\",[t._v(\"Phoenix 最早是 saleforce 的一个开源项目，后来成为 Apache 的顶级项目。\")]),t._v(\" \"),a(\"p\",[t._v(\"Phoenix 构建在 HBase 之上的开源 SQL 层。能够让我们使用标准的 JDBC API 去建表, 插入数据和查询 HBase 中的数据, 从而可以避免使用 HBase 的客户端 API。在我们的应用和 HBase 之间添加了 Phoenix, 并不会降低性能, 而且我们也少写了很多代码。\")]),t._v(\" \"),a(\"p\",[t._v(\"phoneix的本质就是定义了大量的协处理器，使用协处理器帮助我们完成HBase的操作！\")]),t._v(\" \"),a(\"h2\",{attrs:{id:\"二、phoenix-特点\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#二、phoenix-特点\"}},[t._v(\"#\")]),t._v(\" 二、Phoenix 特点\")]),t._v(\" \"),a(\"p\",[t._v(\"将 SQL 查询编译为 HBase 扫描\\n确定扫描 Rowkey 的最佳开始和结束位置\\n扫描并行执行\\n将 where 子句推送到服务器端的过滤器\\n通过协处理器进行聚合操作\\n完美支持 HBase 二级索引创建\\nDML命令以及通过DDL命令创建和操作表和版本化增量更改。\\n容易集成：如Spark，Hive，Pig，Flume和Map Reduce。\")]),t._v(\" \"),a(\"h2\",{attrs:{id:\"三、phoenix-架构\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#三、phoenix-架构\"}},[t._v(\"#\")]),t._v(\" 三、Phoenix 架构\")]),t._v(\" \"),a(\"p\",[a(\"img\",{attrs:{src:\"https://img-blog.csdnimg.cn/20210131165822416.png\",alt:\"\"}})]),t._v(\" \"),a(\"h2\",{attrs:{id:\"四、和hbase中数据的关系映射\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#四、和hbase中数据的关系映射\"}},[t._v(\"#\")]),t._v(\" 四、和Hbase中数据的关系映射\")]),t._v(\" \"),a(\"table\",[a(\"thead\",[a(\"tr\",[a(\"th\",[t._v(\"模型\")]),t._v(\" \"),a(\"th\",[t._v(\"HBase\")]),t._v(\" \"),a(\"th\",[t._v(\"Phoneix(SQL)\")])])]),t._v(\" \"),a(\"tbody\",[a(\"tr\",[a(\"td\",[t._v(\"库\")]),t._v(\" \"),a(\"td\",[t._v(\"namespace\")]),t._v(\" \"),a(\"td\",[t._v(\"database\")])]),t._v(\" \"),a(\"tr\",[a(\"td\",[t._v(\"表\")]),t._v(\" \"),a(\"td\",[t._v(\"table\")]),t._v(\" \"),a(\"td\",[t._v(\"table\")])]),t._v(\" \"),a(\"tr\",[a(\"td\",[t._v(\"列族\")]),t._v(\" \"),a(\"td\",[t._v(\"column Family cf:cq\")]),t._v(\" \"),a(\"td\",[t._v(\"列\")])]),t._v(\" \"),a(\"tr\",[a(\"td\",[t._v(\"列名\")]),t._v(\" \"),a(\"td\",[t._v(\"column Quailfier\")]),t._v(\" \"),a(\"td\")]),t._v(\" \"),a(\"tr\",[a(\"td\",[t._v(\"值\")]),t._v(\" \"),a(\"td\",[t._v(\"value\")]),t._v(\" \"),a(\"td\")]),t._v(\" \"),a(\"tr\",[a(\"td\",[t._v(\"行键\")]),t._v(\" \"),a(\"td\",[t._v(\"rowkey（唯一） dt|area|city|adsid\")]),t._v(\" \"),a(\"td\",[t._v(\"主键(dt,area,city,adsid)\")])])])]),t._v(\" \"),a(\"p\",[t._v(\"​\\tPhoenix 将 HBase 的数据模型映射到关系型模型中！\")]),t._v(\" \"),a(\"p\",[a(\"img\",{attrs:{src:\"https://img-blog.csdnimg.cn/20210131165851572.png\",alt:\"\"}})]),t._v(\" \"),a(\"h2\",{attrs:{id:\"五、phoenix使用场景\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#五、phoenix使用场景\"}},[t._v(\"#\")]),t._v(\" 五、Phoenix使用场景\")]),t._v(\" \"),a(\"h3\",{attrs:{id:\"_5-1-场景一-新建表\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_5-1-场景一-新建表\"}},[t._v(\"#\")]),t._v(\" 5.1 场景一：新建表\")]),t._v(\" \"),a(\"p\",[t._v(\"通过phoneix在hbase中创建表，通过phoneix向hbase的表执行增删改查！\")]),t._v(\" \"),a(\"div\",{staticClass:\"language-sql extra-class\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-sql\"}},[a(\"code\",[a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"--使用默认的0号列族\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"CREATE\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"TABLE\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"IF\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"NOT\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"EXISTS\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"us_population\"')]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"\\n      state \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"CHAR\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"2\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"NOT\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[t._v(\"NULL\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n      city \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"VARCHAR\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"NOT\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[t._v(\"NULL\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n      population \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"BIGINT\")]),t._v(\"\\n      \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"CONSTRAINT\")]),t._v(\" my_pk \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"PRIMARY\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"KEY\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"state\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" city\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n      \\n\"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"--如果希望列族有意义\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"CREATE\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"TABLE\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"IF\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"NOT\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"EXISTS\")]),t._v(\" us_population \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"\\n      state \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"CHAR\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"2\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"NOT\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[t._v(\"NULL\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n      city \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"VARCHAR\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"NOT\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[t._v(\"NULL\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n      info\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"population \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"BIGINT\")]),t._v(\"\\n      \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"CONSTRAINT\")]),t._v(\" my_pk \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"PRIMARY\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"KEY\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"state\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" city\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n\")])])]),a(\"p\",[t._v(\"默认所有的小写，都会转大写！在查询时的小写也会转大写！\")]),t._v(\" \"),a(\"p\",[t._v('如果必须用小写，需要加\"\", 在以后操作时，都需要加\"\",尽量不要使用小写！')]),t._v(\" \"),a(\"h3\",{attrs:{id:\"_5-2-场景二-映射hbase中已有表\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_5-2-场景二-映射hbase中已有表\"}},[t._v(\"#\")]),t._v(\" 5.2 场景二：映射Hbase中已有表\")]),t._v(\" \"),a(\"p\",[t._v(\"hbase中已经存在了一个表，在phoneix中建表，映射上，进行操作！\")]),t._v(\" \"),a(\"p\",[t._v(\"在phoneix中，只读操作！ 创建一个View!\")]),t._v(\" \"),a(\"div\",{staticClass:\"language-sql extra-class\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-sql\"}},[a(\"code\",[a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"CREATE\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"VIEW\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"IF\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"NOT\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"EXISTS\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"t2\"')]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"\\n      id  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"VARCHAR\")]),t._v(\"  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"PRIMARY\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"KEY\")]),t._v(\"  \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n      \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"cf1\"')]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"name\"')]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"VARCHAR\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"cf2\"')]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"age\"')]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"VARCHAR\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"cf2\"')]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"gender\"')]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"VARCHAR\")]),t._v(\" \\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n\")])])]),a(\"p\",[t._v(\"在phoneix中，可读可写操作！ 创建一个Table!\")]),t._v(\" \"),a(\"div\",{staticClass:\"language-sql extra-class\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-sql\"}},[a(\"code\",[a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"CREATE\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"TABLE\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"IF\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"NOT\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"EXISTS\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"t4\"')]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"\\n      id  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"VARCHAR\")]),t._v(\"  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"PRIMARY\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"KEY\")]),t._v(\"  \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n      \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"cf1\"')]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"name\"')]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"VARCHAR\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"cf2\"')]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"age\"')]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"VARCHAR\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"cf2\"')]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"gender\"')]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"VARCHAR\")]),t._v(\" \\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" column_encoded_bytes\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\")])])]),a(\"h2\",{attrs:{id:\"六、phoenix使用语法\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#六、phoenix使用语法\"}},[t._v(\"#\")]),t._v(\" 六、Phoenix使用语法\")]),t._v(\" \"),a(\"p\",[t._v(\"进入Phoenix客户端界面\")]),t._v(\" \"),a(\"div\",{staticClass:\"language- extra-class\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[a(\"code\",[t._v(\"[hadoop@hadoop101 phoenix]$ /opt/module/phoenix/bin/sqlline.py hadoop102,hadoop103,hadoop104:2181\\n\")])])]),a(\"h3\",{attrs:{id:\"_1-显示所有表\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_1-显示所有表\"}},[t._v(\"#\")]),t._v(\" 1）显示所有表\")]),t._v(\" \"),a(\"div\",{staticClass:\"language- extra-class\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[a(\"code\",[t._v(\"!table 或 !tables\\n\")])])]),a(\"h3\",{attrs:{id:\"_2-创建表\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_2-创建表\"}},[t._v(\"#\")]),t._v(\" 2）创建表\")]),t._v(\" \"),a(\"div\",{staticClass:\"language- extra-class\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[a(\"code\",[t._v(\"CREATE TABLE IF NOT EXISTS us_population (\\n      state CHAR(2) NOT NULL,\\n      city VARCHAR NOT NULL,\\n      population BIGINT\\n      CONSTRAINT my_pk PRIMARY KEY (state, city));\\n\")])])]),a(\"p\",[t._v(\"说明:\")]),t._v(\" \"),a(\"ul\",[a(\"li\",[t._v(\"char类型必须添加长度限制\")]),t._v(\" \"),a(\"li\",[t._v(\"varchar 可以不用长度限制\")]),t._v(\" \"),a(\"li\",[t._v(\"主键映射到 HBase 中会成为 Rowkey. 如果有多个主键(联合主键), 会把多个主键的值拼成 rowkey\")]),t._v(\" \"),a(\"li\",[t._v(\"在 Phoenix 中, 默认会把表名,字段名等自动转换成大写. 如果要使用消息, 需要把他们用双引号括起来.\")])]),t._v(\" \"),a(\"h3\",{attrs:{id:\"_3-插入数据\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_3-插入数据\"}},[t._v(\"#\")]),t._v(\" 3）插入数据\")]),t._v(\" \"),a(\"div\",{staticClass:\"language- extra-class\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[a(\"code\",[t._v(\"upsert into us_population values('NY','NewYork',8143197);\\nupsert into us_population values('CA','Los Angeles',3844829);\\nupsert into us_population values('IL','Chicago',2842518);\\n说明: upset可以看成是update和insert的结合体.\\n\")])])]),a(\"h3\",{attrs:{id:\"_4-查询记录\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_4-查询记录\"}},[t._v(\"#\")]),t._v(\" 4）查询记录\")]),t._v(\" \"),a(\"div\",{staticClass:\"language- extra-class\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[a(\"code\",[t._v(\"select * from US_POPULATION;\\nselect * from us_population where state='NY';\\n\")])])]),a(\"p\",[t._v(\"5）删除记录\")]),t._v(\" \"),a(\"div\",{staticClass:\"language- extra-class\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[a(\"code\",[t._v(\"delete from us_population where state='NY';\\n\")])])]),a(\"p\",[t._v(\"6）删除表\")]),t._v(\" \"),a(\"div\",{staticClass:\"language- extra-class\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[a(\"code\",[t._v(\"drop table us_population;\\n\")])])]),a(\"p\",[t._v(\"7）退出命令行\")]),t._v(\" \"),a(\"div\",{staticClass:\"language- extra-class\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[a(\"code\",[t._v(\"! quit\\n\")])])]),a(\"h2\",{attrs:{id:\"七、使用jdbc连接\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#七、使用jdbc连接\"}},[t._v(\"#\")]),t._v(\" 七、使用JDBC连接\")]),t._v(\" \"),a(\"p\",[t._v(\"添加如下依赖：\")]),t._v(\" \"),a(\"div\",{staticClass:\"language-xml extra-class\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-xml\"}},[a(\"code\",[a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"\\x3c!-- https://mvnrepository.com/artifact/org.apache.phoenix/phoenix-core --\\x3e\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),t._v(\"dependency\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),t._v(\"groupId\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\"org.apache.phoenix\"),a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"</\")]),t._v(\"groupId\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),t._v(\"artifactId\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\"phoenix-core\"),a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"</\")]),t._v(\"artifactId\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),t._v(\"version\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\"5.0.0-HBase-2.0\"),a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"</\")]),t._v(\"version\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"</\")]),t._v(\"dependency\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\"\\n\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"\\x3c!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-common --\\x3e\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),t._v(\"dependency\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),t._v(\"groupId\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\"org.apache.hadoop\"),a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"</\")]),t._v(\"groupId\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),t._v(\"artifactId\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\"hadoop-common\"),a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"</\")]),t._v(\"artifactId\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),t._v(\"version\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\"3.1.1\"),a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"</\")]),t._v(\"version\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"</\")]),t._v(\"dependency\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\"\\n\")])])]),a(\"p\",[t._v(\"测试连接：\")]),t._v(\" \"),a(\"div\",{staticClass:\"language-java extra-class\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-java\"}},[a(\"code\",[a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"import\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token namespace\"}},[t._v(\"java\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"sql\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")])]),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"*\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"public\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"class\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"MyPhoenix\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"public\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"static\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"void\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"main\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"String\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\" args\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"throws\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"SQLException\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"ClassNotFoundException\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v('//Class.forName(\"org.apache.phoenix.jdbc.PhoenixDriver\");')]),t._v(\"\\n\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Connection\")]),t._v(\" connection \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"DriverManager\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getConnection\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"jdbc:phoenix:hadoop102:2181\"')]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"String\")]),t._v(\" sql \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"select * from US_POPULATION\"')]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"PreparedStatement\")]),t._v(\" ps \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" connection\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"prepareStatement\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"sql\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"ResultSet\")]),t._v(\" resultSet \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" ps\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"executeQuery\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"while\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"resultSet\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"next\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n        \"),a(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"System\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"out\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"println\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"resultSet\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getString\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"STATE\"')]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+\")]),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"  \"')]),t._v(\"\\n                     \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+\")]),t._v(\" resultSet\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getString\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"CITY\"')]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"  \"')]),t._v(\"\\n                      \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+\")]),t._v(\" resultSet\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getLong\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"POPULATION\"')]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\\n    resultSet\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"close\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n    ps\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"close\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n    connection\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"close\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\")])])])])}),[],!1,null,null,null);s.default=e.exports}}]);","extractedComments":[]}