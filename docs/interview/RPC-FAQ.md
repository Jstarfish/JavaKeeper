---
title: RPC 面试专场
date: 2024-05-31
tags: 
 - RPC
 - Interview
categories: Interview
---

![](https://img.starfish.ink/common/faq-banner.png)

### RPC的基本原理是什么？

RPC（Remote Procedure Call）即远程过程调用，是分布式系统常见的一种通信方法。它允许程序调用另一个地址空间（通常是共享网络的另一台机器上）的过程或函数，而不用程序员显式编码这个远程调用的细节。

其核心目标是让远程服务调用像本地方法调用一样简单。 

> - 除 RPC 之外，常见的多系统数据交互方案还有分布式消息队列、HTTP 请求调用、数据库和分布式缓存等。
> - 其中 RPC 和 HTTP 调用是没有经过中间件的，它们是端到端系统的直接数据交互。

**实现流程**：

1. **客户端发起调用**：通过本地存根（Stub）封装调用信息（方法名、参数等）。
2. **序列化与传输**：将调用信息序列化为字节流，通过网络发送至服务端。
3. **服务端反序列化与执行**：服务端接收请求，反序列化后定位具体服务实现并执行。
4. **返回结果**：服务端将结果序列化后返回客户端，客户端反序列化获取最终结果。

**关键点**：

- **通信协议**：如HTTP/2（gRPC）、TCP（Dubbo）。
- **序列化方式**：如JSON、Protobuf、Thrift。
- **服务治理**：负载均衡、熔断、限流等

> 话术：
>
> 1. RPC是解决分布式系统中**远程服务调用复杂性**的工具，核心目标是让开发者像调用本地方法一样调用远程服务，隐藏网络通信细节。（**一句话定义（10秒抓住核心）**）
>
> 2. RPC框架包含三个核心模块：代理层（生成接口代理）、序列化层（Protobuf/JSON转换）、网络传输层（Netty实现）。 
>
>    调用流程是：客户端代理封装请求→序列化为二进制→经TCP/HTTP2传输→服务端反序列化→执行真实方法→结果原路返回。关键技术是动态代理屏蔽远程调用细节，配合长连接复用提升性能。（**核心原理拆解（展示技术深度）**）
>
> 3. 相比直接使用HTTP（**对比延伸（突出思考广度）**）：
>
>    - RPC优势是性能更高（二进制协议省带宽）、开发更高效（IDL生成代码）、内置服务治理（熔断/负载均衡）
>    - HTTP优势是通用性强（浏览器直接支持）、调试更方便
>    - 在微服务内部通信选RPC（如Dubbo），开放API用HTTP（如SpringCloud OpenFeign）。 
>    - 腾讯的tRPC通过插件化架构解决协议兼容问题，而gRPC强在跨语言支持。
>
> 4. 在电商订单系统中，我用Dubbo实现库存服务调用（**实战结合（证明落地能力）**）： 
>
>    - 问题：HTTP调用库存接口QPS仅2000，超时率15%
>    - 方案：改用Dubbo+Protobuf，Nacos服务发现，随机负载均衡
>    - 难点：解决序列化兼容性（添加@Adaptive注解） 
>    - 结果：QPS提升到12000，超时率降至0.2%，GC次数减少60%



### 为什么我们要用RPC?

在分布式系统架构中，**RPC是一种核心通信机制，用于解决跨进程、跨机器的函数 / 方法调用问题。其存在的核心价值在于将复杂的分布式系统拆解为可协作的服务单元**，同时尽可能让开发者像调用本地函数一样使用远程服务。

以下是使用 RPC 的核心原因及典型场景：

**一、分布式架构的必然选择**

1. **服务拆分与微服务化**

   - **单体应用的瓶颈**：传统单体架构中，所有功能模块耦合在一个进程内，难以扩展、维护和迭代。

   - **分布式拆分的需求**：将系统拆分为独立部署的服务（如用户服务、订单服务、支付服务），每个服务负责单一业务领域，通过 RPC 实现跨服务协作。

   - **示例**：电商系统中，前端请求用户服务查询用户信息，用户服务通过 RPC 调用订单服务获取历史订单数据。

2. **资源隔离与弹性扩展**

   - **按需扩展特定服务**：不同服务的负载可能差异显著（如促销期间订单服务压力远高于用户服务），通过 RPC 解耦后，可独立对高负载服务扩容。

   - **故障隔离**：某个服务故障不会导致整个系统崩溃，仅影响依赖该服务的功能模块（需配合熔断、重试等机制）。

**二、跨技术栈协作的桥梁**

1. **多语言混合开发**

   - 不同服务可采用最适合的语言实现（如 Java 用于业务逻辑、Go 用于高并发场景、Python 用于数据分析），通过 RPC 屏蔽语言差异。

   - **示例**：Java 编写的网关服务通过 RPC 调用 Go 编写的库存服务，获取商品库存信息。

2. **遗留系统集成**

   - 新老系统并存时，通过 RPC 为遗留系统提供统一接口，避免重构成本。

   - **示例**：用 Node.js 开发新前端系统，通过 RPC 调用 COBOL 编写的核心账务系统接口。

**三、高性能与透明化的远程调用**

1. **接近本地调用的开发体验**

   - RPC 框架通过动态代理、代码生成等技术，将远程调用封装为本地函数调用形式，开发者无需关注网络细节（如 Socket 编程、数据序列化）。

   - 伪代码示例：

     ```java
     // 本地调用风格的RPC
     User user = userService.getUser(123); // 实际通过网络调用远程服务
     ```

2. **比 HTTP 更高效的通信协议**

   - 多数 RPC 框架采用二进制协议（如 Protobuf、Thrift），相比 JSON/XML 格式的 HTTP 请求，**传输体积更小、解析更快**，适合高频、大数据量场景。

   - 性能对比：

     | **协议**         | 传输体积 | 解析耗时 | 典型场景         |
     | ---------------- | -------- | -------- | ---------------- |
     | REST（JSON）     | 100KB    | 10ms     | 通用 Web 服务    |
     | gRPC（Protobuf） | 30KB     | 2ms      | 微服务间高频调用 |

**四、典型应用场景**

1. **微服务架构中的服务间通信**

   - 微服务架构中，每个服务通过 RPC 调用上下游服务，形成复杂的调用链路。

   - **案例**：Netflix 的微服务体系通过 Eureka（服务注册）+ Ribbon（负载均衡）+ Feign（RPC 客户端）实现跨服务通信。

2. **云服务与分布式计算**

   - 云计算平台（如 AWS、阿里云）通过 RPC 提供 API 接口（如 EC2 实例管理、S3 存储操作）。

   - 分布式计算框架（如 Hadoop、Spark）通过 RPC 协调节点间任务调度与数据传输。

3. **实时数据处理与流计算**

   - 实时系统中，不同组件（如消息队列、计算引擎、存储系统）通过 RPC 传递实时数据。

   - **案例**：Kafka Streams 通过 RPC 将实时数据流分发到不同计算节点进行处理。

4. **跨数据中心 / 跨地域调用**

   - 全球化业务中，服务部署在多个数据中心，通过 RPC 实现异地容灾或就近访问。

   - **挑战**：需解决跨地域网络延迟（如通过边缘节点缓存热点数据）。

**五、与其他通信方式的对比**

| **维度**     | **RPC**                 | **REST/HTTP**            | **消息队列（如 Kafka）** |
| ------------ | ----------------------- | ------------------------ | ------------------------ |
| **通信模型** | 同步调用（请求 - 响应） | 同步调用（RESTful 风格） | 异步消息传递             |
| **实时性**   | 高（适合即时响应场景）  | 中（受限于 HTTP 协议）   | 低（适合异步处理）       |
| **数据格式** | 二进制（高效）          | 文本（JSON/XML）         | 自定义（二进制 / 文本）  |
| **适用场景** | 微服务间强依赖调用      | 开放 API、跨团队协作     | 异步任务、流量削峰       |

**六、RPC 的核心价值**

1. **架构层面**：支撑分布式系统的服务拆分与协作，提升可扩展性和可维护性。
2. **开发层面**：屏蔽网络复杂性，降低分布式开发门槛，允许混合技术栈。
3. **性能层面**：提供比传统 HTTP 更高效的通信方式，满足高并发、低延迟需求。

**选择建议**：若需要**强一致性、实时响应的服务间调用**，优先选择 RPC；若需要**开放 API、跨团队 / 跨平台协作**，则更适合 REST/HTTP；若业务场景以**异步解耦**为主，可结合消息队列使用。



### RPC需要解决的三个问题？

**一、Call ID 映射（函数标识与路由）**

**问题本质**

本地调用通过函数指针直接寻址，而远程调用中客户端与服务端处于不同地址空间，需建立**函数到唯一标识的映射关系**，确保服务端准确识别目标函数。

**解决方案**

1. **唯一标识符（Call ID）**

   - 为每个函数分配全局唯一 ID（如整数、字符串或 UUID），例如：

     ```python
     # 服务端映射表示例
     {
         "userService.queryUser": 1001,  # 字符串标识
         "orderService.createOrder": 2002
     }
     ```

   - 客户端通过该 ID 指定调用目标，服务端通过 ID 查找对应函数实现。

2. **动态注册与发现**

   - 服务启动时向注册中心（如 Consul、Nacos）注册函数 ID 与地址的映射关系。
   - 客户端通过注册中心获取服务列表及函数 ID 路由规则，实现动态寻址。

**技术挑战**

- **版本兼容**：函数升级时需保留旧 Call ID 或提供兼容映射，避免客户端请求失效。
- **跨语言映射**：不同语言开发的客户端与服务端需统一 ID 规范（如 Thrift 通过 IDL 文件生成一致的 ID）。

**二、序列化与反序列化（数据格式转换）**

**问题本质**

跨进程通信无法直接传递内存对象，且可能存在语言差异（如 Java 对象与 Go 结构体），需将数据结构转换为**通用字节流格式**，确保跨语言、跨平台解析。

**解决方案**

1. **序列化协议选择**

   | **协议** | **特点**                               | **适用场景**           |
   | -------- | -------------------------------------- | ---------------------- |
   | JSON     | 可读性强，解析效率低                   | 轻量级服务、浏览器交互 |
   | Protobuf | 二进制格式，高效压缩，支持自动生成代码 | 高性能、大数据量场景   |
   | Thrift   | 多语言支持，通过 IDL 定义数据结构      | 跨语言微服务架构       |
   | Avro     | 模式动态演变，适合数据格式频繁变更场景 | 日志系统、实时数据管道 |

2. **对象与字节流转换**

   - **客户端**：将参数对象序列化为字节流（如 Java 的`ObjectOutputStream`、Go 的`json.Marshal`）。
   - **服务端**：将字节流反序列化为本地对象（如 Python 的`json.loads`、C++ 的 Protobuf 解析器）。

**技术挑战**

- **性能瓶颈**：高频调用场景下，序列化 / 反序列化可能成为性能短板（如 JSON 解析耗时高于 Protobuf）。
- **数据兼容性**：字段增减或类型变更时，需确保新旧协议兼容（如 Protobuf 的可选字段、JSON 的默认值处理）。

**三、网络传输（数据通信与可靠性）**

**问题本质**

需建立客户端与服务端的**可靠数据传输通道**，解决网络延迟、丢包、连接管理等问题，确保 Call ID 与序列化数据准确传输。

**解决方案**

1. **传输协议选择**
   - **TCP**：面向连接，提供可靠传输（如 gRPC 基于 HTTP/2，Netty 自定义协议）。
   - **UDP**：无连接，适合实时性要求高但允许少量丢包的场景（如游戏状态同步）。
   - **HTTP/2**：多路复用、头部压缩，适合 RESTful 风格的 RPC（如 Spring Cloud Feign）。
2. **网络层核心组件**
   - **客户端负载均衡**：通过轮询、随机或加权最小连接等策略选择目标服务节点（如 Ribbon、Spring Cloud LoadBalancer）。
   - **连接池管理**：复用网络连接，减少 TCP 三次握手开销（如 Hystrix 的连接池配置）。
   - **超时与重试**：设置请求超时时间（如 gRPC 默认 1 秒），失败后按策略重试（如指数退避）。

**技术挑战**

- **网络拥塞**：高并发场景下可能导致传输延迟陡增，需通过流量控制（如 TCP 滑动窗口）或服务降级缓解。
- **防火墙与 NAT 穿透**：跨网络环境调用时，需解决端口限制或使用反向代理（如 Ngrok）。

**总结：RPC 核心技术栈**

| **问题维度**   | **关键技术**                      | **典型工具 / 框架**               |
| -------------- | --------------------------------- | --------------------------------- |
| Call ID 映射   | 唯一 ID 生成、注册中心、动态路由  | Consul、Nacos、Apache ZooKeeper   |
| 序列化反序列化 | Protobuf、JSON、Thrift、Avro      | Google Protobuf、Apache Thrift    |
| 网络传输       | TCP/UDP、HTTP/2、负载均衡、连接池 | gRPC、Netty、Spring Cloud Netflix |

**设计目标**：通过上述技术的有机组合，实现**透明化远程调用**（调用者无需感知网络细节）、**高性能通信**（低延迟、高吞吐）和**强兼容性**（跨语言、跨平台）。实际应用中需根据业务场景（如实时性、数据量、语言栈）选择合适的技术方案，平衡开发成本与系统性能。



### 实现高可用RPC框架需要考虑到的问题

- 既然系统采用分布式架构，那一个服务势必会有多个实例，要解决**如何获取实例的问题**。所以需要一个服务注册中心，比如在Dubbo中，就可以使用Zookeeper作为注册中心，在调用时，从Zookeeper获取服务的实例列表，再从中选择一个进行调用；
- 如何选择实例呢？就要考虑负载均衡，例如dubbo提供了4种负载均衡策略；
- 如果每次都去注册中心查询列表，效率很低，那么就要加缓存；
- 客户端总不能每次调用完都等着服务端返回数据，所以就要支持异步调用；
- 服务端的接口修改了，老的接口还有人在用，这就需要版本控制；
- 服务端总不能每次接到请求都马上启动一个线程去处理，于是就需要线程池；



### 一次完整的 RPC 流程？

1. **代理拦截**：客户端代理拦截本地调用，解析方法和参数。
2. **序列化**：将对象转为字节流（如 Protobuf）。
3. **网络传输**：通过 TCP/HTTP2 发送，处理粘包、负载均衡。
4. **服务端解析**：拆包、反序列化，路由到目标方法。
5. **结果返回**：序列化响应，逆向流程返回客户端。
6. **关键技术**：协议设计、超时重试、流控等。

![](https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E9%9D%A2%E8%AF%95%E7%B2%BE%E8%AE%B2/assets/Ciqc1GABbyeAWysgAAGQtM8Kx4Q574.png)



### 如何提升网络通信性能？

如何提升 RPC 的网络通信性能，这句话翻译一下就是：一个 RPC 框架如何选择高性能的网络编程 I/O 模型？这样一来，和 I/O 模型相关的知识点就是你需要掌握的了。

对于 RPC 网络通信问题，你首先要掌握网络编程中的五个 I/O 模型：

- 同步阻塞 I/O（BIO）

- 同步非阻塞 I/O

- I/O 多路复用（NIO）

- 信号驱动

- 以及异步 I/O（AIO）

但在实际开发工作，最为常用的是 BIO 和 NIO（这两个 I/O 模型也是面试中面试官最常考察候选人的）。

NIO 比 BIO 提高了服务端工作线程的利用率，并增加了一个调度者，来实现 Socket 连接与 Socket 数据读写之间的分离。

在目前主流的 RPC 框架中，广泛使用的也是 I/O 多路复用模型，Linux 系统中的 select、poll、epoll等系统调用都是 I/O 多路复用的机制。

在面试中，对于高级研发工程师的考察，还会有两个技术扩展考核点。

Reactor 模型（即反应堆模式），以及 Reactor 的 3 种线程模型，分别是单线程 Reactor 线程模型、多线程 Reactor 线程模型，以及主从 Reactor 线程模型。

Java 中的高性能网络编程框架 Netty。

可以这么说，在高性能网络编程中，大多数都是基于 Reactor 模式，其中最为典型的是 Java 的 Netty 框架，而 Reactor 模式是基于 I/O 多路复用的，所以，对于 Reactor 和 Netty 的考察也是避免不了的。



### gRPC与HTTP的区别是什么？

HTTP是应用层协议，主要用于传输超文本，而RPC是一种远程过程调用框架，用于分布式系统中的服务间通信。HTTP基于文本传输，而RPC通常使用二进制序列化协议，减少数据传输体积。

在现代分布式系统中，选择 **RPC**（Remote Procedure Call）而非单纯的 **HTTP** 协议，主要出于 **性能、服务治理能力、通信模型灵活性** 以及 **开发效率** 等方面的考量。

| **对比维度**   | **HTTP**                            | **gRPC**                                         |
| -------------- | ----------------------------------- | ------------------------------------------------ |
| **协议设计**   | 基于文本的请求-响应模型（GET/POST） | 基于HTTP/2的二进制分帧协议，支持双向流式通信     |
| **性能**       | 文本解析开销大，性能较低            | 二进制传输，头部压缩，多路复用，延迟更低         |
| **使用场景**   | Web服务、RESTful API                | 微服务间高性能通信、实时数据流（如聊天、视频流） |
| **接口定义**   | 无强制规范                          | 使用Protocol Buffers定义接口，强类型约束         |
| **跨语言支持** | 天然支持                            | 通过Protobuf生成多语言客户端/服务端代码          |



### 为什么用RPC而不是HTTP？

1. **定义抓本质**： "RPC是专门为**服务间高性能通信**设计的方案，核心解决HTTP在内部调用时开发效率低、性能差的问题。"
2. **原理显深度**： "通过动态代理生成存根屏蔽网络细节，用Protobuf二进制序列化减少70%数据传输量，基于Netty长连接复用避免HTTP三次握手开销。"
3. **对比展视野**： "对比HTTP，RPC在微服务内部调用场景有三优势：
   - 性能：Dubbo压测QPS是Feign的3倍
   - 效率：IDL自动生成代码比手写RestTemplate快5倍
   - 治理：原生支持熔断/限流而HTTP需整合Sentinel"
4. **实战证能力**： "在去年物流项目中，我们把订单到仓储服务的调用从HTTP改为Dubbo：
   - 用SPI扩展点解决序列化兼容问题
   - 基于一致性哈希路由保证相同仓库请求落到同一节点
   - 结果：吞吐量从800TPS提到4200TPS，99分位延迟从340ms降到85ms”



### **gRPC的四种通信模式？**

1. 简单RPC（Unary RPC）：客户端发送单个请求，服务端返回单个响应（如函数调用）。
2. 服务端流式RPC：客户端发送请求，服务端返回数据流（如股票实时行情推送）。
3. 客户端流式RPC：客户端持续发送数据流，服务端最终返回响应（如文件分片上传）。
4. 双向流式RPC：双方独立发送和接收数据流，适用于实时交互（如聊天机器人）



### Dubbo的核心组件及工作流程？

**核心组件**：

- **服务提供者（Provider）**：暴露服务接口的实现。
- **服务消费者（Consumer）**：调用远程服务。
- **注册中心（Registry）**：服务注册与发现（如Zookeeper、Nacos）。
- **配置中心**：管理服务配置。

**工作流程**：

1. **服务注册**：Provider启动时向注册中心注册自身信息（IP、端口等）。
2. **服务发现**：Consumer从注册中心获取Provider列表。
3. **负载均衡**：Consumer通过负载均衡策略（如随机、轮询）选择Provider。
4. **远程调用**：通过Netty等通信框架发起RPC调用。



### **如何选择RPC框架？**

| **框架**                   | **特点**                                                    | **适用场景**                   |
| -------------------------- | ----------------------------------------------------------- | ------------------------------ |
| **Dubbo**                  | Java生态成熟，支持服务治理（负载均衡、熔断），依赖Zookeeper | 微服务架构，需复杂服务治理     |
| **gRPC**                   | 高性能、跨语言、支持流式通信，依赖Protobuf                  | 跨语言服务间通信、实时数据传输 |
| **Thrift**                 | 支持多种语言，接口定义语言灵活，性能较高                    | 多语言混合架构、高吞吐量场景   |
| **Spring Cloud OpenFeign** | 基于HTTP，集成Ribbon、Hystrix，易用性强                     | 快速构建微服务，对性能要求不高 |



### **如何优化RPC调用性能？**

1. 序列化优化：选择高效序列化库（如Protobuf、Thrift），减少传输数据量。
2. 网络通信优化：使用HTTP/2或TCP长连接，减少握手开销。
3. 异步调用：异步非阻塞模式提升资源利用率，但需处理回调逻辑。
4. 服务治理：负载均衡（如一致性哈希）、重试机制、熔断降级。
5. 缓存机制：对高频读操作引入本地缓存（Caffeine）或分布式缓存（Redis）



### **RPC中的服务注册与发现原理？**

RPC 的服务注册与发现涉及三个核心角色：

- **服务提供者（Provider）**：发布服务到注册中心，告知自身地址及服务能力。
- **服务消费者（Consumer）**：从注册中心获取服务列表，发起远程调用。
- **注册中心（Registry）**：作为服务的 “地址簿”，存储服务提供者的元数据（如 IP、端口、服务名等），负责服务的注册、发现和管理。

**关键点**：注册中心是服务动态管理的核心，常见实现有 ZooKeeper、Eureka、Nacos 等（可结合项目经验补充具体框架）

**服务注册流程**

1. **服务启动**：
   服务提供者启动时，将自身服务信息（如接口名、IP、端口、版本号等）封装成 **服务元数据**，通过注册接口向注册中心发送注册请求。
2. **存储与更新**：
   注册中心接收请求后，将元数据存储在内存或持久化存储（如 ZooKeeper 的节点）中，并维护服务列表。若服务状态变更（如下线），需主动通知注册中心更新或删除记录。
3. **健康检查**：
   注册中心通过 **心跳机制** 或 **主动探测** 验证服务提供者的存活状态。若提供者超过一定时间未发送心跳，注册中心会标记服务为 “不可用” 并从列表中剔除，避免消费者调用失效服务。

> “服务提供者启动时，会将自身 IP、端口等信息注册到 ZooKeeper（举例），在 /providers 节点下创建临时节点存储元数据。注册中心通过监听节点变化感知服务上下线，并通过心跳检测确保服务可用。”

**服务发现流程**

1. **消费者请求**：
   服务消费者启动时，向注册中心发起 **服务发现请求**，指定所需服务的名称（如 “user-service”）。
2. **获取服务列表**：
   注册中心返回该服务对应的所有可用提供者的元数据（IP、端口等），通常以 **列表形式** 提供。
3. **本地缓存与更新**：
   消费者将服务列表缓存到本地，避免每次调用都访问注册中心，提升性能。注册中心通过 **长连接** 或 **事件监听**（如 ZooKeeper 的 Watch 机制）主动推送服务变更通知，确保消费者缓存实时更新。
4. **负载均衡**：
   消费者从缓存的服务列表中，通过负载均衡策略（如轮询、随机、权重等）选择一个提供者发起调用。

> “消费者启动时向 Nacos（举例）请求获取‘order-service’的可用实例列表，缓存到本地后，通过轮询策略选择一台提供者发起 RPC 调用。当注册中心检测到某提供者下线时，会通过事件通知消费者更新缓存，剔除不可用实例。”



### **CAP理论在RPC中的应用？**

CAP理论指出分布式系统无法同时满足一致性（Consistency）、可用性（Availability）、分区容错性（Partition Tolerance），需根据业务权衡：

- **Zookeeper**：CP系统，保证数据一致性，网络分区时拒绝写请求。
- Eureka：AP系统，优先保证可用性，容忍网络分区，但可能返回旧数据。

**RPC选型建议**：

- 对一致性要求高（如金融交易）：选择Zookeeper作为注册中心。
- 对可用性要求高（如高并发Web服务）：选择Eureka或Nacos
